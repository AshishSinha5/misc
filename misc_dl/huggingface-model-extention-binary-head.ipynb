{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinha/miniconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "# use gpu for torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Fqih Ben Calah is a name of a country.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.1005859375, 0.466064453125, 0.86474609375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Londrina is a city in Indonesia.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.4140625, -0.00347900390625, 1.37890625, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Klang is a city in Japan.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.3759765625, 0.34814453125, 0.8681640625, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luhansk is a name of a country.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.75146484375, 0.7978515625, 1.0927734375, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nagasaki is a city in Turkey.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.046875, -0.38671875, 1.259765625, -0.72314...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   statement  label  \\\n",
       "0  Al Fqih Ben Calah is a name of a country.      0   \n",
       "1           Londrina is a city in Indonesia.      0   \n",
       "2                  Klang is a city in Japan.      0   \n",
       "3            Luhansk is a name of a country.      0   \n",
       "4              Nagasaki is a city in Turkey.      0   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-1.1005859375, 0.466064453125, 0.86474609375,...  \n",
       "1  [-1.4140625, -0.00347900390625, 1.37890625, -1...  \n",
       "2  [-1.3759765625, 0.34814453125, 0.8681640625, -...  \n",
       "3  [-0.75146484375, 0.7978515625, 1.0927734375, -...  \n",
       "4  [-1.046875, -0.38671875, 1.259765625, -0.72314...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "df = pd.read_csv('data/cities_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load gpt-2 model\n",
    "model = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model, device = device)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryHeadModel(\n",
       "  (model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (linear_1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (loss): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extend the model for binary classification\n",
    "class BinaryHeadModel(nn.Module):\n",
    "    def __init__(self, layer_to_use = -4):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.freeze()\n",
    "        self.layer_to_use = layer_to_use\n",
    "        self.input_dim = self.model.transformer.h[self.layer_to_use].ln_2.normalized_shape[0]\n",
    "        # self.input_dim = self.model.lm_head.out_features\n",
    "        self.linear_1 = nn.Linear(self.input_dim, 256)\n",
    "        self.linear_2 = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(**x, output_hidden_states=True, return_dict=True)\n",
    "        # x = self.softmax(x['logits'][0][-1])\n",
    "        x = x.hidden_states[self.layer_to_use][:,-1,:]\n",
    "        # print(x.shape)\n",
    "        x = self.linear_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.linear_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.sigmoid(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def freeze(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def loss_fn(self, y_pred, y_true):\n",
    "        return self.loss(y_pred, y_true)\n",
    "    \n",
    "custom_model = BinaryHeadModel()\n",
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: 0    Al Fqih Ben Calah is a name of a country.\n",
      "1             Londrina is a city in Indonesia.\n",
      "2                    Klang is a city in Japan.\n",
      "3              Luhansk is a name of a country.\n",
      "4                Nagasaki is a city in Turkey.\n",
      "Name: statement, dtype: object\n",
      "{'input_ids': tensor([[ 2348,   376,    80,  4449,  3932,  2199,   993,   318,   257,  1438,\n",
      "           286,   257,  1499,    13],\n",
      "        [   43,   623, 22267,   318,   257,  1748,   287, 16256,    13, 50256,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [   42, 17204,   318,   257,  1748,   287,  2869,    13, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [   43,  7456, 34738,   318,   257,  1438,   286,   257,  1499,    13,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [   45,   363, 33846,   318,   257,  1748,   287,  7137,    13, 50256,\n",
      "         50256, 50256, 50256, 50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], device='cuda:0')}\n",
      "tensor([[0.7125],\n",
      "        [0.9616],\n",
      "        [0.9655],\n",
      "        [0.9678],\n",
      "        [0.9669]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test_input = df['statement'].iloc[0:5]\n",
    "print(f'Statement: {test_input}')\n",
    "test_input = tokenizer(list(test_input), padding=True, return_tensors=\"pt\")\n",
    "test_input = test_input.to(device)\n",
    "print(test_input)\n",
    "test_output = custom_model(test_input)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (800,)\n",
      "X_test shape:  (200,)\n",
      "y_train shape:  (800,)\n",
      "y_test shape:  (200,)\n"
     ]
    }
   ],
   "source": [
    "# get X and y variable\n",
    "X = df['statement'].values\n",
    "y = df['label'].values\n",
    "# split the data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_X = self.X[index]\n",
    "        batch_y = self.y[index]\n",
    "        return batch_X, batch_y    \n",
    "\n",
    "    def preprocess(self, X):\n",
    "        return tokenizer(X, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def collate(self, batch):\n",
    "        X = [item[0] for item in batch]\n",
    "        X = self.preprocess(X).to(device)\n",
    "        y = torch.tensor([item[1] for item in batch], dtype = torch.float).to(device)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset[0] = ('United States is a name of a city.', 0)\n",
      "test_dataset[0] = ('Japan is a name of a country.', tensor(1., device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# create train and test dataset\n",
    "train_dataset = dataset(X_train, y_train)\n",
    "test_dataset = dataset(X_test, y_test)\n",
    "\n",
    "print(f\"{train_dataset[0] = }\")\n",
    "print(f\"{test_dataset[0] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.9540480375289917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:01,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 10, Loss: 0.8070427775382996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:02, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 20, Loss: 0.6789127588272095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:03,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:04,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 30, Loss: 0.7118586301803589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:05, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 40, Loss: 0.6950407028198242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:06,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.27it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, Loss: 0.8260173201560974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:01,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 10, Loss: 0.7586684226989746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:02,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:02, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 20, Loss: 0.7162606716156006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:03,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:03, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 30, Loss: 0.6944011449813843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:04,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:05, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 40, Loss: 0.7130075693130493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:06,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.62it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 0, Loss: 0.6595249176025391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 10, Loss: 0.6845293641090393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:02,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:02,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 20, Loss: 0.6926208138465881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:03,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:03,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 30, Loss: 0.6696198582649231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:04,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:05, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 40, Loss: 0.7456796169281006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:06,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "optimizer = optim.AdamW(custom_model.parameters(), lr=5e-5, eps=1e-8)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate)\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = custom_model(x)\n",
    "        loss = custom_model.loss_fn(torch.squeeze(y_pred, dim = -1), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "            with torch.no_grad():\n",
    "                test_dataloder = DataLoader(test_dataset, \n",
    "                                          batch_size=len(test_dataset), \n",
    "                                          shuffle=False, \n",
    "                                          collate_fn=test_dataset.collate)\n",
    "                x_test, y_test = next(iter(test_dataloder))\n",
    "                y_pred = custom_model(x_test).detach().cpu().numpy()\n",
    "                y_pred = np.argmax(y_pred, axis=1)\n",
    "                print(f\"Test Accuracy: {accuracy_score(y_test.detach().cpu().numpy(), y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9529, 0.9631, 0.9685, 0.9492, 0.9691, 0.6772, 0.9659, 0.9665, 0.9732,\n",
       "        0.9686, 0.9479, 0.9657, 0.9526, 0.9712, 0.9713, 0.9688],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(y_pred, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
