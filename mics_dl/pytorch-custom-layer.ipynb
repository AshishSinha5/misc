{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "torch.cuda.is_available() = True\n",
      "torch.cuda.device_count() = 1\n",
      "torch.cuda.get_device_name(0) = 'NVIDIA T1200 Laptop GPU'\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # Get PyTorch and CUDA version\n",
    "print(f\"{torch.cuda.is_available() = }\") # Check that CUDA works\n",
    "print(f\"{torch.cuda.device_count() = }\") # Check how many CUDA capable devices you have\n",
    "# Print device human readable names\n",
    "print(f\"{torch.cuda.get_device_name(0) = }\")\n",
    "# Add more lines with +1 like get_device_name(3), get_device_name(4) if you have more devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(0)\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_layer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_feat, out_feat))\n",
    "        self.bias = nn.Parameter(torch.randn(out_feat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.matmul(x, self.weight)\n",
    "        print(f'Shape after matmul with weights - {out.shape}')\n",
    "        out = out + self.bias\n",
    "        print(f'Shape after after adding bias - {out.shape}')\n",
    "        out = nn.ReLU()(out)\n",
    "        print(f'Shape after ReLu operation - {out.shape}')\n",
    "        return out\n",
    "\n",
    "\n",
    "class custom_clf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(30, 20)\n",
    "        self.l2 = nn.Linear(20, 10)\n",
    "        # add a custom layer object\n",
    "        self.custom_layer = my_layer(10, 3)\n",
    "        print(f'Model Instantiated \\n{self}')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.custom_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after matmul with weights - torch.Size([10])\n",
      "Shape after after adding bias - torch.Size([10])\n",
      "Shape after ReLu operation - torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3100, 0.0000, 0.0000, 8.2378, 0.0000, 0.0000, 2.4701, 3.4011, 0.0000,\n",
       "        0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_layer = my_layer(20, 10)\n",
    "test_tensor = torch.FloatTensor(torch.randn(20))\n",
    "custom_layer.forward(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Instantiated \n",
      "custom_clf(\n",
      "  (l1): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (l2): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (custom_layer): my_layer()\n",
      ")\n",
      "Shape after matmul with weights - torch.Size([2, 3])\n",
      "Shape after after adding bias - torch.Size([2, 3])\n",
      "Shape after ReLu operation - torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4589, 3.2610, 0.0000],\n",
       "        [0.9169, 4.7479, 0.2257]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model = custom_clf()\n",
    "test_tensor_2 =torch.FloatTensor(torch.randn(2,30))\n",
    "custom_model.forward(test_tensor_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "### Dense Dirichlet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseDirichletLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.dense = nn.Linear(in_feat, out_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'Shape of X - {x.shape}')\n",
    "        output = self.dense(x)\n",
    "        print(f'Shape pf output - {output.shape}')\n",
    "        evidence = torch.exp(output)\n",
    "        print(f'Shape of Evidence - {evidence.shape}')\n",
    "        alpha = evidence + 1\n",
    "        print(f'Shape of alpha - {alpha.shape}')\n",
    "        prob = alpha / torch.sum(alpha, dim=1, keepdim=True)\n",
    "        print(f'Shape of prob - {prob.shape}')\n",
    "        return prob, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clf_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28*28, 100)\n",
    "        self.l2 = nn.Linear(100, 50)\n",
    "        self.dirichlet_layer = DenseDirichletLayer(50, 10)\n",
    "        print(f'Model Instantiated \\n{self}')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        prob, alpha = self.dirichlet_layer(x)\n",
    "        return prob, alpha\n",
    "    \n",
    "    def loss(self, alpha, label):\n",
    "        \n",
    "        S = torch.sum(alpha, axis=1, keepdim=True)\n",
    "        m = alpha/S\n",
    "\n",
    "        A = torch.sum((label - m)**2, axis=1, keepdim=True)\n",
    "        B = torch.sum(alpha*(S - alpha)/(S*S*(S+1)), axis=1, keepdim=True)\n",
    "        \n",
    "        alpha_hat = label + (1-label)*alpha\n",
    "        C = self.KL(alpha_hat)\n",
    "        C = torch.mean(C, axis = 1)\n",
    "        return torch.mean(A + B + C, axis = 1)\n",
    "    \n",
    "    def KL(self, alpha):\n",
    "        beta = torch.FloatTensor(torch.ones((1, alpha.shape[1])))\n",
    "        S_alpha = torch.sum(alpha, axis = 1, keepdim=True)\n",
    "        S_beta = torch.sum(beta, axis = 1, keepdim=True)\n",
    "        lnB = torch.lgamma(S_alpha) - torch.sum(torch.lgamma(alpha), axis = 1, keepdim=True)\n",
    "        lnB_uni = torch.sum(torch.lgamma(beta), axis=1, keepdim=True) - torch.lgamma(S_beta)\n",
    "        \n",
    "        dg0  = torch.digamma(S_alpha)\n",
    "        dg1 = torch.digamma(alpha)\n",
    "\n",
    "        kl = torch.sum((alpha - beta)*(dg1-dg0), axis = 0, keepdim=True) + lnB + lnB_uni\n",
    "        return kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X - torch.Size([2, 100])\n",
      "Shape pf output - torch.Size([2, 10])\n",
      "Shape of Evidence - torch.Size([2, 10])\n",
      "Shape of alpha - torch.Size([2, 10])\n",
      "Shape of prob - torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0726, 0.0989, 0.0666, 0.0874, 0.1117, 0.1626, 0.0912, 0.1133, 0.1283,\n",
       "          0.0673],\n",
       "         [0.1116, 0.0804, 0.0844, 0.0791, 0.1345, 0.0922, 0.0783, 0.0673, 0.0921,\n",
       "          0.1801]], grad_fn=<DivBackward0>),\n",
       " tensor([[1.5740, 2.1445, 1.4433, 1.8954, 2.4225, 3.5260, 1.9781, 2.4571, 2.7811,\n",
       "          1.4597],\n",
       "         [2.2750, 1.6390, 1.7199, 1.6130, 2.7409, 1.8782, 1.5950, 1.3711, 1.8769,\n",
       "          3.6706]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.randn(2, 100)\n",
    "dirichlet_layer = DenseDirichletLayer(100, 10)\n",
    "dirichlet_layer(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Instantiated \n",
      "clf_model(\n",
      "  (l1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (l2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (dirichlet_layer): DenseDirichletLayer(\n",
      "    (dense): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "test_tensor_2 = torch.randn(2, 28*28)\n",
    "dirichlet_model = clf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X - torch.Size([2, 50])\n",
      "Shape pf output - torch.Size([2, 10])\n",
      "Shape of Evidence - torch.Size([2, 10])\n",
      "Shape of alpha - torch.Size([2, 10])\n",
      "Shape of prob - torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1037, 0.0954, 0.0940, 0.1032, 0.0921, 0.1076, 0.0997, 0.0977, 0.1091,\n",
       "          0.0976],\n",
       "         [0.0904, 0.1050, 0.1073, 0.0961, 0.0950, 0.0919, 0.0972, 0.0966, 0.1116,\n",
       "          0.1089]], grad_fn=<DivBackward0>),\n",
       " tensor([[1.9460, 1.7905, 1.7635, 1.9376, 1.7283, 2.0188, 1.8714, 1.8343, 2.0468,\n",
       "          1.8310],\n",
       "         [1.7761, 2.0623, 2.1079, 1.8873, 1.8657, 1.8044, 1.9098, 1.8971, 2.1925,\n",
       "          2.1385]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_model(test_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
